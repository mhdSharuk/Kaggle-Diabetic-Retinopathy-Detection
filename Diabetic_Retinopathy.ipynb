{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetic_Retinopathy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2s9ogM-hYpQ",
        "colab_type": "text"
      },
      "source": [
        "Importing kaggle.json file from my kaggle account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pya1nIHWrJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5FiuJghe5o",
        "colab_type": "text"
      },
      "source": [
        "Making a kaggle directory in root,\n",
        "Copying kaggle.json file \n",
        "Giving permission to kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHoOd-dW1Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wGxGLhLhwvt",
        "colab_type": "text"
      },
      "source": [
        "Downloading Diabetic Retinopathy data from kaggle CLI "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iWTz4zJXFKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c aptos2019-blindness-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDAoKtwah3Us",
        "colab_type": "text"
      },
      "source": [
        "Making train and test images directory to extract and save the images to their respective directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUCRhfJkbSSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train_images\n",
        "!mkdir test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5R4SDVWiAGC",
        "colab_type": "text"
      },
      "source": [
        "Extracting the zip files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Ys3XAcdPQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile as zf\n",
        "\n",
        "with zf('/content/train_images.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('/content/train_images/')\n",
        "  \n",
        "print(\"Train extract finished...\")\n",
        "!rm -rf train_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poE3Ewm2nydV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zf('/content/test_images.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('/content/test_images/')\n",
        "  \n",
        "print(\"Test extract finished...\")\n",
        "!rm -rf test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq3e-g9aiGEq",
        "colab_type": "text"
      },
      "source": [
        "Importing required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUejaEJ_fuF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization,Activation,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from matplotlib import pyplot as plt\n",
        "import shutil\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyoOPfdug6va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./train_images')\n",
        "train_images = os.listdir()\n",
        "os.chdir('./../test_images')\n",
        "test_images = os.listdir()\n",
        "os.chdir('./../')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20cYkQNihQyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv = pd.read_csv('./train.csv')\n",
        "test_csv  = pd.read_csv('./test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TPYPKihecbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5870a7ad-f2a2-450a-91db-c02076366dad"
      },
      "source": [
        "test_csv.shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1928, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89p0QlxyfToS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1787380-8730-485e-be4d-49906a11aaaa"
      },
      "source": [
        "len(test_images)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEGRLdFjijbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv['id_code'] = train_csv['id_code'].map(lambda x : x+'.png')\n",
        "test_csv['id_code'] = test_csv['id_code'].map(lambda x : x+'.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYKrACqXu--X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv['diagnosis'] = train_csv['diagnosis'].apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uI64ej-6wOj",
        "colab_type": "text"
      },
      "source": [
        "Splitting the CSV to Training and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjGF3kwI6UeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(train_csv.id_code,train_csv.diagnosis,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aljJOoSeW0fu",
        "colab_type": "text"
      },
      "source": [
        "Converting the Fundus Image to \n",
        "\n",
        "1.   Gray Scale and Masking all the pixel values in that image and stacking the 3 color channels again to get the real image\n",
        "2.    Removing the black contours from the image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wRVEefuTVGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_image_from_gray(img, tol=7):\n",
        "    path = f'./test_images/{label}'\n",
        "    img = cv2.imread(path)\n",
        "    if img.ndim == 2:\n",
        "        mask = img > tol\n",
        "        return img[np.ix_(mask.any(1), mask.any(0))]\n",
        "    elif img.ndim == 3:\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        mask = gray_img > tol\n",
        "        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
        "        if (check_shape == 0):\n",
        "            return img\n",
        "        else:\n",
        "            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
        "            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
        "            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
        "            img = np.stack([img1, img2, img3], axis=-1)\n",
        "            dim = (240,120)\n",
        "            img = cv2.resize(img,dim,interpolation = cv2.INTER_AREA)\n",
        "        return img\n",
        "\n",
        "      \n",
        "def circle_crop(img):\n",
        "    \n",
        "    img = crop_image_from_gray(img)\n",
        "  \n",
        "    height, width, depth = img.shape\n",
        "    largest_side = np.max((height, width))\n",
        "    img = cv2.resize(img, (largest_side, largest_side))\n",
        "\n",
        "    height, width, depth = img.shape\n",
        "\n",
        "    x = int(width / 2)\n",
        "    y = int(height / 2)\n",
        "    r = np.amin((x, y))\n",
        "\n",
        "    circle_img = np.zeros((height, width), np.uint8)\n",
        "    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n",
        "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
        "    img = crop_image_from_gray(img)\n",
        "\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGFhcTvoXNto",
        "colab_type": "text"
      },
      "source": [
        "1.  Converting the Fundus Images to green color channel so that we can the arteries and veins clearly\n",
        "2.   Resizing it into (224,224) so that it matches with the DenseNet121 Convolution Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3XvUwvAvCkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def img_to_green(img):\n",
        "  \n",
        "    circle_crop(img)\n",
        "    dim = (224,224)\n",
        "    image = cv2.imread(path)\n",
        "    image = image[:,:,1]\n",
        "    clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8,8))\n",
        "    image = cv2.medianBlur(image,3)\n",
        "    image = cv2.equalizeHist(image)\n",
        "    image = clahe.apply(image)\n",
        "    image = cv2.resize(image,dim,interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC_C0nS3YEKW",
        "colab_type": "text"
      },
      "source": [
        "Overall Preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4S3c8V4Sd1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = img_to_green(img)\n",
        "    cv2.imwrite(path,img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CaXPZxLYHZb",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM_CpmjZf67x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "for label in train_images:\n",
        "    path = f'./train_images/{label}'\n",
        "    preprocess_image(path)\n",
        "    print(i)\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JfU7z1uYL2n",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the testing image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8WPqgQcgy21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "for label in test_images:\n",
        "    path = f'./test_images/{label}'\n",
        "    preprocess_image(path)\n",
        "    print(i)\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WszXvZj4TNB",
        "colab_type": "text"
      },
      "source": [
        "Distribution of Diagnosis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIPi2Ih9xZkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(train_csv['diagnosis'])\n",
        "plt.hist(test_csv['diagnosis'])\n",
        "plt.title(\"Diagnosis Distribution\",color='white')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leraFlff4Ey-",
        "colab_type": "code",
        "outputId": "bc0432b2-19c1-4dbd-ff77-30b19567103d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generator = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                              validation_split=0.1,\n",
        "                              horizontal_flip=True,\n",
        "                              vertical_flip=True,\n",
        "                              )\n",
        "train_path = './train_images/'\n",
        "train_generator = generator.flow_from_dataframe(\n",
        "             dataframe = train_csv,\n",
        "             directory = train_path,\n",
        "             subset='training',\n",
        "             target_size=(224,224),\n",
        "             x_col = 'id_code',\n",
        "             y_col = 'diagnosis',\n",
        "             class_mode='categorical',\n",
        "             shuffle=True,\n",
        "             batch_size = 32)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3296 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvk5KHRW7Z5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "477e4a34-cf6f-4375-b6e9-6febb9a50e8b"
      },
      "source": [
        "validation_generator = generator.flow_from_dataframe(dataframe=train_csv,\n",
        "                                                    directory=train_path,\n",
        "                                                    subset='validation',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    x_col='id_code',\n",
        "                                                    y_col='diagnosis',\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=32)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 366 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmOF5f0HcMlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e9fa95f-64f8-4e30-81e3-c8c4f357da33"
      },
      "source": [
        "test_path = './test_images/'\n",
        "test_generator = generator.flow_from_dataframe(dataframe=test_csv,\n",
        "                                             directory=test_path,\n",
        "                                             target_size=(224,224),\n",
        "                                             x_col='id_code',\n",
        "                                             y_col=None,\n",
        "                                             class_mode=None,\n",
        "                                             shuffle=False,\n",
        "                                             batch_size=32)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1928 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2avUjka1dM8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(224,224,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tgmdcHcrxBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "79a1ae9b-b348-447b-ecea-609f22b58c29"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 222, 222, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 222, 222, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 111, 111, 64)      18496     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 111, 111, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 109, 109, 64)      36928     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 109, 109, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 186624)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               95552000  \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 95,620,133\n",
            "Trainable params: 95,620,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfGhCZnIqXjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4-iIBLq43z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_NeUCTirOJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "dcef8ef3-4aac-497c-e784-109a427bd89b"
      },
      "source": [
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 970s 9s/step - loss: 1.6345 - acc: 0.5573 - val_loss: 1.2543 - val_acc: 0.6562\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 959s 9s/step - loss: 0.9320 - acc: 0.6711 - val_loss: 1.1444 - val_acc: 0.6705\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 959s 9s/step - loss: 0.8590 - acc: 0.6945 - val_loss: 0.9883 - val_acc: 0.7045\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 959s 9s/step - loss: 0.8299 - acc: 0.6996 - val_loss: 0.9013 - val_acc: 0.7216\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 956s 9s/step - loss: 0.8083 - acc: 0.7057 - val_loss: 0.8866 - val_acc: 0.7131\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 956s 9s/step - loss: 0.7922 - acc: 0.7148 - val_loss: 0.8727 - val_acc: 0.7188\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 958s 9s/step - loss: 0.7727 - acc: 0.7248 - val_loss: 0.8140 - val_acc: 0.7216\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 958s 9s/step - loss: 0.7558 - acc: 0.7178 - val_loss: 0.7732 - val_acc: 0.7273\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 957s 9s/step - loss: 0.7337 - acc: 0.7367 - val_loss: 0.7274 - val_acc: 0.7244\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 956s 9s/step - loss: 0.7214 - acc: 0.7367 - val_loss: 0.7096 - val_acc: 0.7358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0de2a07cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leUUxijTrmT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('diabetic_retinopathy.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_8XA6NsSO37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26bb2736-bd83-4b37-f89a-751626a9f794"
      },
      "source": [
        "model.evaluate_generator(generator=validation_generator,steps=STEP_SIZE_TEST)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7134855672717094, 0.73333335]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJ9RI2hSi7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0256d9ac-7a2e-4eb9-b3cf-fa3fa2ab0959"
      },
      "source": [
        "test_generator.reset()\n",
        "\n",
        "pred=model.predict_generator(test_generator,\n",
        "                             verbose=1)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61/61 [==============================] - 121s 2s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1NowLyg_C2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80df8e8b-0051-44a4-d630-821037588f1f"
      },
      "source": [
        "print(STEP_SIZE_TEST)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6FNnthsfn41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec76bd81-a82d-42e0-edf9-cd12e38d2a57"
      },
      "source": [
        "len(pred)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzVBVj3KUJpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxV7qzhCdrCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "299123a7-906d-41d9-f205-f253ef1538d9"
      },
      "source": [
        "len(predicted_class_indices)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfrCNP8FdxDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2772ab4a-db4a-4a46-9da7-10e26c3333fd"
      },
      "source": [
        "len(test_images)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cw4DY88VjT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predicted_class_indices)):\n",
        "  print(predicted_class_indices[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOWziQwJVqXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def submit(predictions):\n",
        "  sub = pd.read_csv('./sample_submission.csv')\n",
        "  sub['diagnosis'] = predictions\n",
        "  sub.to_csv('./sub.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RReiCuV6di_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit(predicted_class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWuzmxNgdo73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}